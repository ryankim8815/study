# 선형 회귀

## 학습 목표: k-최근접 이웃 회귀와 선형 회귀 알고리즘의 차이를 이해하고 사용할 수 있다.

### 1. k-최근접 이웃의 한계

- 설명
  - k-최근접 이웃 회귀는 가장 가까운 샘플을 찾아 타깃의 평균을 구함
  - 즉, 새로운 샘플이 훈련 세트의 범위를 벗어나면 엉뚱한 값을 예측할 수 있음

### 2. 선형 회귀(Linear regression)

- 설명
  - 비교적 간단하고 성능이 뛰어나 널리 사용되는 회귀 알고리즘
  - 특성이 하나인 경우 **직선**을 학습하는 알고리즘
  - 사이킷런은 sklearn.linear_model 패키지 내 LinearRegression 클래스로 선형 회기 알고리즘이 구현되어 있음

### 3. 다항 회귀(Polynomial regression)

- 설명
  - 다항식(Polynomial)을 사용한 선형 회귀
  - 예시와 같이 선점도에서 훈련 세트의 분포가 직선이 아닌 2차 곡선의 형태일 때 활용
